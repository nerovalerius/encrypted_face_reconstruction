{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-SF0fkU5qyJ"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eladrich/pixel2style2pixel/blob/master/notebooks/inference_playground.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Uuviq3qQkUFy"
   },
   "outputs": [],
   "source": [
    "# All the rights belongs to the following github page -> https://github.com/eladrich/pixel2style2pixel\n",
    "import os\n",
    "os.chdir('.')\n",
    "CODE_DIR = 'pixel2style2pixel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6788,
     "status": "ok",
     "timestamp": 1638875285436,
     "user": {
      "displayName": "Armin Ahmet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01876910559981814557"
     },
     "user_tz": -60
    },
    "id": "QQ6XEmlHlXbk",
    "outputId": "dfd9a7cd-fe9f-4af7-ede4-2d909d1eba0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pixel2style2pixel' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/eladrich/pixel2style2pixel.git $CODE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6709,
     "status": "ok",
     "timestamp": 1638875343477,
     "user": {
      "displayName": "Armin Ahmet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01876910559981814557"
     },
     "user_tz": -60
    },
    "id": "JaRUFuVHkzye",
    "outputId": "963c6e9d-e20e-4f35-8555-7f98e0da048e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-07 14:16:58--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211207%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211207T131657Z&X-Amz-Expires=300&X-Amz-Signature=a9291c21c7d8797de1ebe04e948201adf1d87208edbc7464f305121299d4e41f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-12-07 14:16:58--  https://github-releases.githubusercontent.com/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211207%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211207T131657Z&X-Amz-Expires=300&X-Amz-Signature=a9291c21c7d8797de1ebe04e948201adf1d87208edbc7464f305121299d4e41f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.110.154, 185.199.111.154, 185.199.108.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.110.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 77854 (76K) [application/octet-stream]\n",
      "Saving to: ‘ninja-linux.zip.1’\n",
      "\n",
      "ninja-linux.zip.1   100%[===================>]  76.03K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2021-12-07 14:16:59 (10.8 MB/s) - ‘ninja-linux.zip.1’ saved [77854/77854]\n",
      "\n",
      "[sudo] password for nero: "
     ]
    }
   ],
   "source": [
    "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
    "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
    "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "23baccYQlU9E"
   },
   "outputs": [],
   "source": [
    "os.chdir(f'./{CODE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "error",
     "timestamp": 1638875469805,
     "user": {
      "displayName": "Armin Ahmet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01876910559981814557"
     },
     "user_tz": -60
    },
    "id": "d13v7In0kTJn",
    "outputId": "3015f8c1-1769-4bd4-edad-480f6bf434bc"
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import time\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from datasets import augmentations\n",
    "from utils.common import tensor2im, log_input_image\n",
    "from models.psp import pSp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRjtz6uLkTJs"
   },
   "source": [
    "## Step 1: Select Experiment Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "xxAO6yL35qyS"
   },
   "outputs": [],
   "source": [
    "#@title Select which experiment you wish to perform inference on: { run: \"auto\" }\n",
    "experiment_type = 'celebs_super_resolution' #@param ['ffhq_encode', 'ffhq_frontalize', 'celebs_sketch_to_face', 'celebs_seg_to_face', 'celebs_super_resolution', 'toonify']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4etDz82xkTJz"
   },
   "source": [
    "## Step 2: Download Pretrained Models \n",
    "As part of this repository, we provide pretrained models for each of the above experiments. We'll download the model for the selected experiments as save it to the folder `../pretrained_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KSnjlBZOkTJ0"
   },
   "outputs": [],
   "source": [
    "def get_download_model_command(file_id, file_name):\n",
    "    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n",
    "    current_directory = os.getcwd()\n",
    "    save_path = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"pretrained_models\")\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m4sjldFMkTJ5"
   },
   "outputs": [],
   "source": [
    "MODEL_PATHS = {\n",
    "    \"ffhq_encode\": {\"id\": \"1bMTNWkh5LArlaWSc_wa8VKyq2V42T2z0\", \"name\": \"psp_ffhq_encode.pt\"},\n",
    "    \"ffhq_frontalize\": {\"id\": \"1_S4THAzXb-97DbpXmanjHtXRyKxqjARv\", \"name\": \"psp_ffhq_frontalization.pt\"},\n",
    "    \"celebs_sketch_to_face\": {\"id\": \"1lB7wk7MwtdxL-LL4Z_T76DuCfk00aSXA\", \"name\": \"psp_celebs_sketch_to_face.pt\"},\n",
    "    \"celebs_seg_to_face\": {\"id\": \"1VpEKc6E6yG3xhYuZ0cq8D2_1CbT0Dstz\", \"name\": \"psp_celebs_seg_to_face.pt\"},\n",
    "    \"celebs_super_resolution\": {\"id\": \"1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu\", \"name\": \"psp_celebs_super_resolution.pt\"},\n",
    "    \"toonify\": {\"id\": \"1YKoiVuFaqdvzDP5CZaqa3k5phL-VDmyz\", \"name\": \"psp_ffhq_toonify.pt\"}\n",
    "}\n",
    "\n",
    "path = MODEL_PATHS[experiment_type]\n",
    "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7277,
     "status": "ok",
     "timestamp": 1638799784857,
     "user": {
      "displayName": "Armin Ahmet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01876910559981814557"
     },
     "user_tz": -60
    },
    "id": "jQ31J_m7kTJ8",
    "outputId": "748f20b2-3076-48da-abcd-17b513afcc1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-07 19:38:29--  https://docs.google.com/uc?export=download&confirm=fgU7&id=1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu\n",
      "Resolving docs.google.com (docs.google.com)... 142.251.37.14, 2a00:1450:4016:80b::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.251.37.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-04-bo-docs.googleusercontent.com/docs/securesc/us1ke5qsgedv1j90dmp0vkck36i9ve87/4pn4ut1l0a3dfat2sobnas3hpcitnb41/1638902250000/17930361707849974000/00687600454740158457Z/1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu?e=download [following]\n",
      "--2021-12-07 19:38:29--  https://doc-04-bo-docs.googleusercontent.com/docs/securesc/us1ke5qsgedv1j90dmp0vkck36i9ve87/4pn4ut1l0a3dfat2sobnas3hpcitnb41/1638902250000/17930361707849974000/00687600454740158457Z/1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu?e=download\n",
      "Resolving doc-04-bo-docs.googleusercontent.com (doc-04-bo-docs.googleusercontent.com)... 142.251.36.193, 2a00:1450:4016:809::2001\n",
      "Connecting to doc-04-bo-docs.googleusercontent.com (doc-04-bo-docs.googleusercontent.com)|142.251.36.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://docs.google.com/nonceSigner?nonce=qu713upaj0so0&continue=https://doc-04-bo-docs.googleusercontent.com/docs/securesc/us1ke5qsgedv1j90dmp0vkck36i9ve87/4pn4ut1l0a3dfat2sobnas3hpcitnb41/1638902250000/17930361707849974000/00687600454740158457Z/1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu?e%3Ddownload&hash=hib91hbhuqsmmfjvqdd8smlslv6hu3i8 [following]\n",
      "--2021-12-07 19:38:29--  https://docs.google.com/nonceSigner?nonce=qu713upaj0so0&continue=https://doc-04-bo-docs.googleusercontent.com/docs/securesc/us1ke5qsgedv1j90dmp0vkck36i9ve87/4pn4ut1l0a3dfat2sobnas3hpcitnb41/1638902250000/17930361707849974000/00687600454740158457Z/1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu?e%3Ddownload&hash=hib91hbhuqsmmfjvqdd8smlslv6hu3i8\n",
      "Connecting to docs.google.com (docs.google.com)|142.251.37.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://doc-04-bo-docs.googleusercontent.com/docs/securesc/us1ke5qsgedv1j90dmp0vkck36i9ve87/4pn4ut1l0a3dfat2sobnas3hpcitnb41/1638902250000/17930361707849974000/00687600454740158457Z/1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu?e=download&nonce=qu713upaj0so0&user=00687600454740158457Z&hash=ga7pk3ec1n1jmd1klne89gr08u6atb0t [following]\n",
      "--2021-12-07 19:38:30--  https://doc-04-bo-docs.googleusercontent.com/docs/securesc/us1ke5qsgedv1j90dmp0vkck36i9ve87/4pn4ut1l0a3dfat2sobnas3hpcitnb41/1638902250000/17930361707849974000/00687600454740158457Z/1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu?e=download&nonce=qu713upaj0so0&user=00687600454740158457Z&hash=ga7pk3ec1n1jmd1klne89gr08u6atb0t\n",
      "Connecting to doc-04-bo-docs.googleusercontent.com (doc-04-bo-docs.googleusercontent.com)|142.251.36.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1201515702 (1.1G) [application/octet-stream]\n",
      "Saving to: ‘/home/nero/GitHub/encrypted_face_reconstruction/pixel2style2pixel/pretrained_models/psp_celebs_super_resolution.pt’\n",
      "\n",
      "/home/nero/GitHub/e 100%[===================>]   1.12G  24.0MB/s    in 50s     \n",
      "\n",
      "2021-12-07 19:39:20 (23.0 MB/s) - ‘/home/nero/GitHub/encrypted_face_reconstruction/pixel2style2pixel/pretrained_models/psp_celebs_super_resolution.pt’ saved [1201515702/1201515702]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{download_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Tozsg81kTKA"
   },
   "source": [
    "## Step 3: Define Inference Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIhyc7RqkTKB"
   },
   "source": [
    "Below we have a dictionary defining parameters such as the path to the pretrained model to use and the path to the image to perform inference on.  \n",
    "While we provide default values to run this script, feel free to change as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2kE5y1-skTKC"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_DATA_ARGS = {\n",
    "    \"ffhq_encode\": {\n",
    "        \"model_path\": \"pretrained_models/psp_ffhq_encode.pt\",\n",
    "        \"image_path\": \"notebooks/images/input_img.jpg\",\n",
    "        \"transform\": transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "    },\n",
    "    \"ffhq_frontalize\": {\n",
    "        \"model_path\": \"pretrained_models/psp_ffhq_frontalization.pt\",\n",
    "        \"image_path\": \"notebooks/images/input_img.jpg\",\n",
    "        \"transform\": transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "    },\n",
    "    \"celebs_sketch_to_face\": {\n",
    "        \"model_path\": \"pretrained_models/psp_celebs_sketch_to_face.pt\",\n",
    "        \"image_path\": \"notebooks/images/input_sketch.jpg\",\n",
    "        \"transform\": transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor()])\n",
    "    },\n",
    "    \"celebs_seg_to_face\": {\n",
    "        \"model_path\": \"pretrained_models/psp_celebs_seg_to_face.pt\",\n",
    "        \"image_path\": \"notebooks/images/input_mask.png\",\n",
    "        \"transform\": transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            augmentations.ToOneHot(n_classes=19),\n",
    "            transforms.ToTensor()])\n",
    "    },\n",
    "    \"celebs_super_resolution\": {\n",
    "        \"model_path\": \"pretrained_models/psp_celebs_super_resolution.pt\",\n",
    "        \"image_path\": \"notebooks/images/input_img.jpg\",\n",
    "        \"transform\": transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            augmentations.BilinearResize(factors=[16]),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "    },\n",
    "    \"toonify\": {\n",
    "        \"model_path\": \"pretrained_models/psp_ffhq_toonify.pt\",\n",
    "        \"image_path\": \"notebooks/images/input_img.jpg\",\n",
    "        \"transform\": transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IzUHoD9ukTKG"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[experiment_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C8S-rjjarPW"
   },
   "source": [
    "We need to verify that the model was downloaded correctly. All of our models should weigh approximately 1.12GB.  \n",
    "Note that if the file weighs several KBs, you most likely encounter a \"quota exceeded\" error from Google Drive. In that case, you should try downloading the model again after a few hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tdQkdQb-agB9"
   },
   "outputs": [],
   "source": [
    "if os.path.getsize(EXPERIMENT_ARGS['model_path']) < 1000000:\n",
    "  raise ValueError(\"Pretrained model was unable to be downlaoded correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAWrUehTkTKJ"
   },
   "source": [
    "## Step 4: Load Pretrained Model\n",
    "We assume that you have downloaded all relevant models and placed them in the directory defined by the above dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1t-AOhP1kTKJ"
   },
   "outputs": [],
   "source": [
    "model_path = EXPERIMENT_ARGS['model_path']\n",
    "ckpt = torch.load(model_path, map_location='cpu')\n",
    "opts = ckpt['opts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EMKhWoFKkTKS"
   },
   "outputs": [],
   "source": [
    "# update the training options\n",
    "opts['checkpoint_path'] = model_path\n",
    "if 'learn_in_w' not in opts:\n",
    "    opts['learn_in_w'] = False\n",
    "if 'output_size' not in opts:\n",
    "    opts['output_size'] = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5059,
     "status": "ok",
     "timestamp": 1638808777429,
     "user": {
      "displayName": "Armin Ahmet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01876910559981814557"
     },
     "user_tz": -60
    },
    "id": "6hccfNizkTKW",
    "outputId": "e4ee4dcd-23eb-4c73-ca61-490f081da244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pSp from checkpoint: pretrained_models/psp_celebs_super_resolution.pt\n",
      "Model successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "opts = Namespace(**opts)\n",
    "net = pSp(opts)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "print('Model successfully loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10984,
     "status": "ok",
     "timestamp": 1638799856077,
     "user": {
      "displayName": "Armin Ahmet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01876910559981814557"
     },
     "user_tz": -60
    },
    "id": "y244_ejy9Drx",
    "outputId": "6b7be798-0015-499d-ef73-bcb0976244d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-07 14:19:08--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
      "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
      "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64040097 (61M)\n",
      "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
      "\n",
      "shape_predictor_68_ 100%[===================>]  61.07M  17.8MB/s    in 3.4s    \n",
      "\n",
      "2021-12-07 14:19:11 (17.8 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "!bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hJ9Ce1aYzmFF"
   },
   "outputs": [],
   "source": [
    "def run_alignment(image_path):\n",
    "  import dlib\n",
    "  from scripts.align_all_parallel import align_face\n",
    "  predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "  aligned_image = align_face(filepath=image_path, predictor=predictor)\n",
    "  print(\"Aligned image has shape: {}\".format(aligned_image.size))\n",
    "  return aligned_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "v5POMJ5YkTKl"
   },
   "outputs": [],
   "source": [
    "def run_on_batch(inputs, net, latent_mask=None):\n",
    "    if latent_mask is None:\n",
    "        result_batch = net(inputs.to(\"cuda\").float(), randomize_noise=False)\n",
    "    else:\n",
    "        result_batch = []\n",
    "        for image_idx, input_image in enumerate(inputs):\n",
    "            # get latent vector to inject into our input image\n",
    "            vec_to_inject = np.random.randn(1, 512).astype('float32')\n",
    "            _, latent_to_inject = net(torch.from_numpy(vec_to_inject).to(\"cuda\"),\n",
    "                                      input_code=True,\n",
    "                                      return_latents=True)\n",
    "            # get output image with injected style vector\n",
    "            res = net(input_image.unsqueeze(0).to(\"cuda\").float(),\n",
    "                      latent_mask=latent_mask,\n",
    "                      inject_latent=latent_to_inject)\n",
    "            result_batch.append(res)\n",
    "        result_batch = torch.cat(result_batch, dim=0)\n",
    "    return result_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12670,
     "status": "ok",
     "timestamp": 1638799902285,
     "user": {
      "displayName": "Armin Ahmet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01876910559981814557"
     },
     "user_tz": -60
    },
    "id": "SIrUNKD0sLzC",
    "outputId": "a0095cb4-311c-4afc-c280-a9c1a1b921df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepface in /home/nero/.local/lib/python3.8/site-packages (0.0.68)\n",
      "Requirement already satisfied: gdown>=3.10.1 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (4.2.0)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (1.21.4)\n",
      "Requirement already satisfied: opencv-python>=3.4.4 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (4.5.4.60)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (2.7.0)\n",
      "Requirement already satisfied: Flask>=1.1.2 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (2.0.2)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (0.1.1)\n",
      "Requirement already satisfied: keras>=2.2.0 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (2.7.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (1.3.4)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (8.4.0)\n",
      "Requirement already satisfied: retina-face>=0.0.1 in /home/nero/.local/lib/python3.8/site-packages (from deepface) (0.0.5)\n",
      "Requirement already satisfied: filelock in /home/nero/.local/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (3.4.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown>=3.10.1->deepface) (1.14.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/lib/python3/dist-packages (from gdown>=3.10.1->deepface) (2.22.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/nero/.local/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (4.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from tensorflow>=1.9.0->deepface) (0.34.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (12.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (2.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (4.0.1)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (0.22.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.13.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.42.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (3.19.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/nero/.local/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.0.0)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /home/nero/.local/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (2.0.2)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/nero/.local/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (8.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /home/nero/.local/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /home/nero/.local/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (3.0.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/nero/.local/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/nero/.local/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/nero/.local/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/nero/.local/lib/python3.8/site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.3.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/nero/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (45.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/nero/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/nero/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/nero/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/nero/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (2.3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nero/.local/lib/python3.8/site-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/nero/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/nero/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.8.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.2.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/nero/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/nero/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.0.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 529662,
     "status": "ok",
     "timestamp": 1638811085934,
     "user": {
      "displayName": "Armin Ahmet",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01876910559981814557"
     },
     "user_tz": -60
    },
    "id": "OfeUV0GL7G5Q",
    "outputId": "1f883b48-a4d7-4ed5-bbe0-1f3765008293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# paths of our images \n",
    "plain_img_root = \"/home/nero/GitHub/encrypted_face_reconstruction/original_and_generated_faces/original/plain\"\n",
    "l_img_root = \"/home/nero/GitHub/encrypted_face_reconstruction/original_and_generated_faces/original/l_encrypted\"\n",
    "r_img_root =  \"/home/nero/GitHub/encrypted_face_reconstruction/original_and_generated_faces/original/r_encrypted\"\n",
    "output_root = \"/home/nero/GitHub/encrypted_face_reconstruction/original_and_generated_faces/original/output\"\n",
    "\n",
    "# use FaceNet model for deepnet\n",
    "model_name = \"Facenet\"\n",
    "model = DeepFace.build_model(model_name)\n",
    "\n",
    "#EXPERIMENT_DATA_ARGS[experiment_type][\"image_path\"] = file\n",
    "EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[experiment_type]\n",
    "\n",
    "          \n",
    "\n",
    "########################################################################\n",
    "# loop over our faces - using the folder structure of the plain faces\n",
    "# should be the same structure also for the encrypted images\n",
    "########################################################################\n",
    "for root, dirs, files in os.walk(plain_img_root):\n",
    "    \n",
    "    # go over all faces inside one folder\n",
    "    for file in files:\n",
    "        \n",
    "        # get the name and id of our plain face in order to\n",
    "        # later check if the correct encrypted faces are used\n",
    "        plain_img_name = file.split(\"_\")\n",
    "        plain_img_path = root + \"/\" + file   \n",
    "        plain_img = Image.open(plain_img_path)\n",
    "\n",
    "        # get the folder id and the file id\n",
    "        plain_folder_id = plain_img_name[0]\n",
    "        plain_img_id = plain_img_name[1].split(\".\")[0]\n",
    "\n",
    "        #################################################################\n",
    "        # read in encrypted faces in one folder\n",
    "        # but only take the face with the same id as the original image\n",
    "        #################################################################\n",
    "        for root_l, dirs_l, files_l in os.walk(r_img_root):\n",
    "\n",
    "            # go over all faces inside one folder\n",
    "            for file_l in files_l:\n",
    "\n",
    "                    l_img_id = file_l.split(\"_\")\n",
    "\n",
    "                    # does our encrypted image have the same id as our plain image?\n",
    "                    # if yes. go out of both for loops (folder loop and file loop)\n",
    "                    if l_img_id[0] == plain_folder_id and l_img_id[1] == plain_img_id :\n",
    "                        l_encrypted_img_path = root_l + \"/\" + file_l\n",
    "                        break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "        # Visualize the input \n",
    "        #image_path = EXPERIMENT_DATA_ARGS[experiment_type][\"image_path\"]\n",
    "\n",
    "        # load our encrypted image\n",
    "        l_encrypted_img = Image.open(l_encrypted_img_path)\n",
    "\n",
    "        # some options from the neural net model\n",
    "        # what does label_nc? \n",
    "        # convert image\n",
    "        if opts.label_nc == 0:\n",
    "            l_encrypted_img = l_encrypted_img.convert(\"RGB\")\n",
    "        else:\n",
    "            l_encrypted_img = l_encrypted_img.convert(\"L\")\n",
    "\n",
    "        \"\"\"\n",
    "        # run_aligment cannot run when face is not detected thats why when face not detected by the program we will pass the other image.\n",
    "        if experiment_type not in [\"celebs_sketch_to_face\", \"celebs_seg_to_face\"]:\n",
    "        input_image = run_alignment(image_path)\n",
    "        else:\n",
    "        input_image = original_image\n",
    "        \"\"\"\n",
    "\n",
    "        ########################################################################\n",
    "        # FACE GENERATION WITH P2S2P GaN Network\n",
    "        ########################################################################\n",
    "\n",
    "        # resize image\n",
    "        l_encrypted_img.resize((256, 256))\n",
    "\n",
    "        # apply some transforms\n",
    "        img_transforms = EXPERIMENT_ARGS['transform']\n",
    "        l_encrypted_img_transformed = img_transforms(l_encrypted_img)\n",
    "\n",
    "        # which function we use from the neural net\n",
    "        if experiment_type in [\"celebs_sketch_to_face\", \"celebs_seg_to_face\"]:\n",
    "            latent_mask = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "        else:\n",
    "            latent_mask = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tic = time.time()\n",
    "            result_img = run_on_batch(l_encrypted_img_transformed.unsqueeze(0), net, latent_mask)[0]\n",
    "            toc = time.time()\n",
    "            #print('Inference took {:.4f} seconds.'.format(toc - tic))\n",
    "\n",
    "        l_encrypted_vis_img = log_input_image(l_encrypted_img_transformed, opts)\n",
    "        generated_img = tensor2im(result_img)\n",
    "\n",
    "\n",
    "        ########################################\n",
    "        # combine faces into 1 image\n",
    "        ########################################\n",
    "        combined_img_array = np.concatenate([plain_img.resize((256,256)),          # the plain face\n",
    "                             np.array(l_encrypted_vis_img.resize((256, 256))),     # the encrypted face, somehow transformed\n",
    "                             np.array(generated_img.resize((256, 256)))], axis=1)  # the generated face\n",
    "\n",
    "        ########################################\n",
    "        # compare face similarty with deepface\n",
    "        ########################################\n",
    "\n",
    "        # create output face folders\n",
    "        try:\n",
    "            os.mkdir(output_root + file.split('_')[0])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # save generated images\n",
    "        generated_img_path = output_root + file.split('_')[0] + \"/\" + file[:-4] + \"_gen.jpg\"\n",
    "\n",
    "        # save generated image\n",
    "        generated_img.save(generated_img_path)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AGwejL1A_s7"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "imgplot = plt.imshow(original_image)\n",
    "ax.set_title('Before')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "imgplot = plt.imshow(output_image)\n",
    "imgplot.set_clim(0.0, 0.7)\n",
    "ax.set_title('After')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkDF8pavIIzC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGw0B9zf0WvH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "p2s2p_GaN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
